# Crypto-LOB Micro-Move Classifier
*Predict the next-second direction of the mid-price from limit-order-book snapshots*

---

## 1 Â· Whatâ€™s inside

| Section | TL;DR |
|---------|-------|
| **Goal** | 3-class classification **â†‘ / â†’ / â†“** of `midpoint(t + 1 s) âˆ’ midpoint(t)` |
| **Data** | Public **High-Frequency Crypto LOB** (Bybit). We use **BTC _1sec.csv** â€” â‰ˆ 1 M rows Ã— 150 LOB columns |
| **Features** | 30-second rolling window â†’ `30 Ã— 153 = 4590` float32 features |
| **Model** | 3-layer MLP (512-256-3) Â· CrossEntropy Â· Macro F1 |
| **Pipeline** | `download â†’ preprocess â†’ train â†’ export(ONNX) â†’ Triton CPU` â€” reproducible with **Poetry + Hydra + DVC + MLflow** |
| **Latency** | â‰ˆ 0.8 ms / 1 sample on Ryzen 5950X via Triton (onnxruntime backend) |

---

## 2 Â· Repo layout
```bash
crypto-lob-micro-move/
â”œâ”€ src/cryptolob/
â”‚ â”œâ”€ commands.py # Fire CLI
â”‚ â”œâ”€ data/ # download / preprocess
â”‚ â”œâ”€ datamodules/ # LightningDataModule
â”‚ â”œâ”€ models/ # Lightning MLP
â”‚ â”œâ”€ export/ # ckpt â†’ ONNX
â”‚ â””â”€ serving/ # Triton repo builder
â”œâ”€ configs/ # Hydra YAMLs
â”œâ”€ artifacts/ # checkpoints, ONNX
â”œâ”€ docker/triton/models/ # generated model-repo
â”œâ”€ dvc.yaml
â””â”€ README.md
```

---
# Part I Â· Setup ðŸ› ï¸

> Requires Python 3.10+ and Docker. **No GPU needed.**

```bash
git clone https://github.com/you/crypto-lob-micro-move.git
cd crypto-lob-micro-move

# Python deps
curl -sSL https://install.python-poetry.org | python -
poetry install

# Dev helpers
pre-commit install
dvc init            # if you forked; otherwise `dvc pull`
```
Part II Â· Train
```bash
# 0 Â· data
poetry run clob download

# 1 Â· build 30-s windows
poetry run clob preprocess data.lookback=30

# 2 Â· train 5 epochs (MLflow logs in ./mlruns)
poetry run clob train model.n_inputs=4590 max_epochs=5 batch_size=256

key=value after the command are Hydra overrides; combine as you like.
Full pipeline via DVC:
dvc repro train
```
#Part III Â· Production preparation

Lightning ckpt â†’ ONNX
poetry run clob export --ckpt=artifacts/best.ckpt

Build Triton CPU repo
```bash
Artifacts delivered with the model:
artifacts/model.onnx
docker/triton/models/micromove/
    â”œâ”€ 1/model.onnx
    â””â”€ config.pbtxt
```
#Part IV Â· Infer
```bash
1 Â· launch Triton CPU-only
docker run -p8000:8000 -p8001:8001 \
       -v $(pwd)/docker/triton/models:/models \
       ghcr.io/triton-inference-server/server:24.03-py3 \
       tritonserver --model-repository=/models

2 Â· call REST
import requests, json, numpy as np
vec = np.random.randn(1, 4590).astype("float32").tolist()

payload = {
  "inputs": [{
      "name": "features",
      "shape": [1, 4590],
      "datatype": "FP32",
      "data": vec
  }]
}

r = requests.post("http://localhost:8000/v2/models/micromove/infer",
                  headers={"Content-Type":"application/json"},
                  data=json.dumps(payload))
print(r.json())      # logits for classes [â†“, â†’, â†‘]

Input format â€” flattened window of 30 LOB snapshots (4590 floats).
```
